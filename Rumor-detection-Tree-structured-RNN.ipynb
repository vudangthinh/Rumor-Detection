{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.aclweb.org/anthology/P18-1184.pdf\n",
    "# https://github.com/aykutfirat/pyTorchTree\n",
    "# https://github.com/liamge/Pytorch_ReNN\n",
    "\n",
    "# https://github.com/inyukwo1/tree-lstm\n",
    "# https://github.com/dasguptar/treelstm.pytorch/blob/master/treelstm/model.py\n",
    "\n",
    "# https://github.com/unbounce/pytorch-tree-lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import random\n",
    "from treelib import Node, Tree\n",
    "import networkx as nx\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, Dataset, DataLoader, random_split\n",
    "\n",
    "import nltk\n",
    "from nltk.util import ngrams\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from ekphrasis.classes.preprocessor import TextPreProcessor\n",
    "from ekphrasis.classes.tokenizer import SocialTokenizer\n",
    "from ekphrasis.dicts.emoticons import emoticons\n",
    "import gensim\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tqdm import tqdm, trange, tqdm_notebook\n",
    "\n",
    "from IPython.core.debugger import set_trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    'data_dir': '/data/rumor_detection/data/rumor_acl/rumor_detection_acl2017/twitter15/',\n",
    "    'tweet_content_file': 'tweet_contents.txt',\n",
    "    'tree_dir': 'tree',\n",
    "    'label_file': 'label.txt',\n",
    "    'w2v': 'twitter_preprocess_3_w2c_400.txt',\n",
    "\n",
    "    'max_graph_size': 50,\n",
    "    'K': 2,\n",
    "    'hidden_dim': 200,\n",
    "    'target_size': 4,\n",
    "    'batch_size': 8,\n",
    "    'learning_rate': 1e-3,\n",
    "    'n_epoches': 70,\n",
    "    'logging_steps': 100,\n",
    "    'do_eval': True,\n",
    "    'aggregator': 'mean',\n",
    "    'n_splits': 5,\n",
    "    'seed': 1234,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed=1234):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "seed_everything(args['seed'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_text_processor():\n",
    "    text_processor = TextPreProcessor(\n",
    "            normalize=['url', 'email', 'percent', 'money', 'phone', 'user',\n",
    "                       'time', 'date', 'number'],\n",
    "            fix_html=True,\n",
    "            segmenter=\"twitter\",\n",
    "            corrector=\"twitter\",\n",
    "\n",
    "            unpack_hashtags=True,\n",
    "            unpack_contractions=True,\n",
    "            spell_correct_elong=True,\n",
    "\n",
    "            # tokenizer=SocialTokenizer(lowercase=True).tokenize,\n",
    "            tokenizer=RegexpTokenizer(r'\\w+').tokenize,\n",
    "\n",
    "            dicts=[emoticons]\n",
    "        )\n",
    "\n",
    "    return text_processor\n",
    "\n",
    "def remove_stopword(tokens):\n",
    "    stop_words = stopwords.words('english')\n",
    "#     stop_words.append('url')\n",
    "    return [word for word in tokens if word not in stop_words]\n",
    "\n",
    "def stemming(tokens, ps):\n",
    "    tokens = [ps.stem(token) for token in tokens]\n",
    "    return tokens\n",
    "\n",
    "def lemmatizer(tokens, wn):\n",
    "    tokens = [wn.lemmatize(token) for token in tokens]\n",
    "    return tokens\n",
    "\n",
    "def remove_last_url(tokens):\n",
    "    if len(tokens) > 0 and tokens[-1] == 'url':\n",
    "        return tokens[:-1]\n",
    "    else:\n",
    "        return tokens\n",
    "    \n",
    "def pre_process(s):\n",
    "    text = s.content\n",
    "    text = text.replace(\"\\/\", '/')\n",
    "    text = text.lower()\n",
    "\n",
    "    tokens = text_processor.pre_process_doc(text)\n",
    "    tokens = remove_stopword(tokens)\n",
    "    tokens = stemming(tokens, ps)\n",
    "    tokens = lemmatizer(tokens, wn)\n",
    "    # tokens = remove_last_url(tokens)\n",
    "    n_grams = set.union(set(ngrams(tokens, 1)), set(ngrams(tokens, 2)))\n",
    "    return n_grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading twitter - 1grams ...\n",
      "Reading twitter - 2grams ...\n",
      "Reading twitter - 1grams ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/kits/anaconda3/lib/python3.7/site-packages/ekphrasis/classes/exmanager.py:14: FutureWarning: Possible nested set at position 42\n",
      "  regexes = {k.lower(): re.compile(self.expressions[k]) for k, v in\n"
     ]
    }
   ],
   "source": [
    "word_vectors = KeyedVectors.load_word2vec_format(args['data_dir'] + args['w2v'], binary=False)\n",
    "embed_dim = word_vectors.vector_size\n",
    "text_processor = create_text_processor()\n",
    "ps = nltk.PorterStemmer()\n",
    "wn = nltk.WordNetLemmatizer()\n",
    "\n",
    "def load_tweet_content(tweet_content_file):\n",
    "    def embed_content(s):\n",
    "        tokens = s.content_tokens\n",
    "        content_embedding = torch.tensor([word_vectors[token] for token in tokens if token in word_vectors], dtype=torch.float)\n",
    "        content_embedding = torch.mean(content_embedding, axis=0)\n",
    "        if torch.isnan(content_embedding).any():\n",
    "            content_embedding = torch.zeros((embed_dim, ))\n",
    "        return content_embedding\n",
    "\n",
    "    content_df = pd.read_csv(tweet_content_file, sep='\\t', header=None, names=['id', 'content'])\n",
    "    content_df['content_tokens'] = content_df.apply(pre_process, axis=1)\n",
    "    content_df['content_embedding'] = content_df.apply(embed_content, axis=1)\n",
    "    content_dict = {row['id']:row['content_embedding'] for i, row in content_df.iterrows()}\n",
    "    \n",
    "    return content_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_rumor_trees(tree_dir_path, content_dict):\n",
    "    trees = {}\n",
    "    for f in os.listdir(tree_dir_path):\n",
    "        file_path = os.path.join(tree_dir_path, f)\n",
    "\n",
    "        if os.path.isfile(file_path) and '.txt' in file_path:\n",
    "            tree = Tree()\n",
    "            tweet_ids = []\n",
    "            root_id = int(f.split('.')[0])\n",
    "            tweet_ids.append(root_id)\n",
    "            if root_id in content_dict:\n",
    "                content = content_dict[root_id]\n",
    "            else:\n",
    "                content = torch.zeros((embed_dim, ))\n",
    "            tree.create_node(tag=root_id, identifier=root_id, data=content)\n",
    "            with open(file_path, 'r') as file:\n",
    "                for line in file:\n",
    "                    line_arr = line.split(\"'\")\n",
    "                    if 'ROOT' not in line:\n",
    "                        user1 = int(line_arr[1])\n",
    "                        tweet1 = int(line_arr[3])\n",
    "                        user2 = int(line_arr[7])\n",
    "                        tweet2 = int(line_arr[9])\n",
    "                        \n",
    "                        if tweet2 not in tweet_ids: \n",
    "                            tweet_ids.append(tweet2)\n",
    "                        \n",
    "                        if tweet2 not in tree.nodes:\n",
    "                            if tweet2 in content_dict:\n",
    "                                content = content_dict[tweet2]\n",
    "                            else:\n",
    "                                content = torch.zeros((embed_dim, ))\n",
    "                            tree.create_node(tag=tweet2, identifier=tweet2, parent=tweet1, data=content)\n",
    "                \n",
    "                tweet_ids.reverse()\n",
    "                trees[root_id] = (tweet_ids, tree)\n",
    "        \n",
    "    return trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_labels(label_file):\n",
    "    label_df = pd.read_csv(label_file, sep=':', header=None, names=['label', 'id'])\n",
    "    label_df['label'] = label_df['label'].map({'unverified': 0, 'non-rumor': 1, 'true': 2, 'false': 3})\n",
    "    label_dict = {row['id']:row['label'] for i, row in label_df.iterrows()}\n",
    "    \n",
    "    return label_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RumorDataset(Dataset):\n",
    "    def __init__(self, ids_list, tree_list, label_list):\n",
    "        super(RumorDataset, self).__init__()\n",
    "        self.ids_list = ids_list\n",
    "        self.tree_list = tree_list\n",
    "        self.label_list = label_list\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        return (self.ids_list[item], self.tree_list[item], self.label_list[item])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RumorModel(nn.Module):\n",
    "    def __init__(self, embed_dim, hidden_dim, target_size):\n",
    "        super(RumorModel, self).__init__()\n",
    "        \n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        self.gru = nn.GRUCell(embed_dim, hidden_dim, bias=False)\n",
    "        self.linear_out = nn.Linear(hidden_dim, target_size)\n",
    "        \n",
    "    def forward(self, node_list, tree):\n",
    "        node_out_dict = {}\n",
    "        for node in node_list:\n",
    "            node_input = tree.get_node(node).data\n",
    "            node_hidden = torch.zeros((self.hidden_dim, ))\n",
    "            childrens = tree.children(node)\n",
    "            for child in childrens:\n",
    "                node_hidden += node_out_dict[child.identifier]\n",
    "                \n",
    "            node_out_dict[node] = self.gru(node_input.unsqueeze(0), node_hidden.unsqueeze(0)).squeeze()\n",
    "            \n",
    "        last_node_hidden = node_out_dict[node_list[-1]]\n",
    "        output = self.linear_out(last_node_hidden)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_dict = load_tweet_content(os.path.join(args['data_dir'], args['tweet_content_file']))\n",
    "trees = load_rumor_trees(os.path.join(args['data_dir'], args['tree_dir']), content_dict)\n",
    "label_dict = load_labels(os.path.join(args['data_dir'], args['label_file']))\n",
    "ids_list = []\n",
    "tree_list = []\n",
    "label_list = []\n",
    "\n",
    "for root, (tweet_ids, tree) in trees.items():\n",
    "    ids_list.append(tweet_ids)\n",
    "    tree_list.append(tree)\n",
    "    label_list.append(label_dict[root])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:   0%|          | 0/70 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Fold 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05c7155fbde84030a6957867dcf1005f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:   1%|▏         | 1/70 [00:17<20:16, 17.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0, train loss 1.1083291183438218\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74960b5ffdd54b089227019e52c9b72d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:   3%|▎         | 2/70 [00:35<20:03, 17.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1, train loss 1.1082199005945492\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2fd1987f57d4c48bf434af1e34e795f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:   4%|▍         | 3/70 [00:52<19:41, 17.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2, train loss 1.108195432284583\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab532480a902443c9a0008aa2bfd16fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:   6%|▌         | 4/70 [01:10<19:24, 17.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3, train loss 1.10818769317246\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9ad0fb2316c4abfb16b94df9ff52332",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:   7%|▋         | 5/70 [01:28<19:01, 17.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4, train loss 1.108184933984167\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2bcc24558644a1eb9ef737af72ebc1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:   9%|▊         | 6/70 [01:45<18:41, 17.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5, train loss 1.1081838314188959\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12b34d55990947f68a8a72f6b9644f23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  10%|█         | 7/70 [02:04<18:45, 17.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 6, train loss 1.108183347261869\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd30c1a29aa24836a5c4348e322e5ebe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  11%|█▏        | 8/70 [02:22<18:38, 18.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 7, train loss 1.1081831255744183\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58b050bc45ff46e6ad96d5be01a9914e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  13%|█▎        | 9/70 [02:40<18:13, 17.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 8, train loss 1.1081830177069032\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59acb1ba2c3045328be4972b8bcf8deb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  14%|█▍        | 10/70 [02:58<18:04, 18.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 9, train loss 1.1081829648590602\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e95b3485a91476597a834b671a12979",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  16%|█▌        | 11/70 [03:16<17:47, 18.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 10, train loss 1.1081829390384246\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a5f1f98ede347bb876e4e56d1ab6dd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  17%|█▋        | 12/70 [03:37<18:14, 18.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 11, train loss 1.1081829274553359\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e921e6f740b426b8cbf5ad0c83b1aad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  19%|█▊        | 13/70 [03:59<18:49, 19.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 12, train loss 1.1081829222268582\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ec63263e00a44e69ce7b934c8c67b8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  20%|██        | 14/70 [04:22<19:29, 20.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 13, train loss 1.1081829186875811\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "246a3a26eed6426d83c03a092cd4cae8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  21%|██▏       | 15/70 [04:44<19:18, 21.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 14, train loss 1.1081829148265514\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a405e2447b44755b2b2e999fa06c510",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  23%|██▎       | 16/70 [05:04<18:40, 20.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 15, train loss 1.108182915952685\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdcc2751c6c14268ba413c4ba3a77574",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  24%|██▍       | 17/70 [05:23<17:48, 20.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 16, train loss 1.1081829169179425\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5097b9edfe064d2fa39cf0d918211d06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  26%|██▌       | 18/70 [05:42<17:12, 19.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 17, train loss 1.1081829149874276\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5567acd31c24411ba61debf5244a725a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  27%|██▋       | 19/70 [05:59<16:19, 19.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 18, train loss 1.1081829147461133\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d5e5fcf893e4b11a2773fedae8a0678",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-8558cf849b8a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/kits/anaconda3/lib/python3.7/site-packages/torch/optim/adamw.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m                 \u001b[0;31m# Perform stepweight decay\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m                 \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weight_decay'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m                 \u001b[0;31m# Perform optimization step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "splits = list(StratifiedKFold(n_splits=args['n_splits'], shuffle=True, random_state=args['seed']).split(tree_list, label_list))\n",
    "\n",
    "for idx, (train_idx, val_idx) in enumerate(splits):\n",
    "    print('Train Fold {}'.format(idx))\n",
    "    \n",
    "    train_ids_list = [ids_list[i] for i in train_idx]\n",
    "    train_tree_list = [tree_list[i] for i in train_idx]\n",
    "    train_label_list = [label_list[i] for i in train_idx]\n",
    "    \n",
    "    valid_ids_list = [ids_list[i] for i in val_idx]\n",
    "    valid_tree_list = [tree_list[i] for i in val_idx]\n",
    "    valid_label_list = [label_list[i] for i in val_idx]\n",
    "    \n",
    "    model = RumorModel(embed_dim=embed_dim, hidden_dim=args['hidden_dim'], \n",
    "                       target_size=args['target_size'])\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.AdamW(params=model.parameters(), lr=args['learning_rate'])\n",
    "\n",
    "    for epoch in trange(args['n_epoches'], desc='Epoch'):\n",
    "        model.train()\n",
    "        tr_loss = 0.0\n",
    "\n",
    "        for tweet_ids, tree, label in tqdm_notebook(zip(train_ids_list, train_tree_list, train_label_list)):\n",
    "            preds = model(tweet_ids, tree)\n",
    "            loss = criterion(preds.unsqueeze(0), torch.tensor(label).unsqueeze(0))\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            tr_loss += loss.item()\n",
    "\n",
    "        train_loss = tr_loss / len(label_list)\n",
    "        print(f\"Epoch {epoch}, train loss {train_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
